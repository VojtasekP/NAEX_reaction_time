{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaction Time Experiment: 2^k Factorial Design with Blocking\n",
    "\n",
    "This notebook analyzes a reaction time experiment using a 2^7 factorial design with 4 operators as blocks.\n",
    "\n",
    "## Experimental Design\n",
    "\n",
    "### Factors (k = 7):\n",
    "1. **Minimum delay**: -1 = 0.5s, +1 = 2.0s\n",
    "2. **Maximum delay**: -1 = 3.0s, +1 = 7.0s\n",
    "3. **Frame motion**: -1 = static, +1 = shaking\n",
    "4. **Background**: -1 = white, +1 = random colors\n",
    "5. **Font scale**: -1 = small, +1 = large\n",
    "6. **Text color**: -1 = black, +1 = random colors\n",
    "7. **Text motion**: -1 = static, +1 = moving\n",
    "\n",
    "### Blocks (Operators):\n",
    "- Sabina\n",
    "- Florentin\n",
    "- Francisco\n",
    "- Petr\n",
    "\n",
    "### Response:\n",
    "- Reaction time (ms) - 10 repetitions per condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom io import StringIO\n\n# Define file paths with local-first approach and GitHub fallback\ndata_files = {\n    'Florentin': 'reaction_time_measurements_Florentin.csv',\n    'Francisco': 'reaction_time_measurements_Francisco.csv',\n    'Sabina': 'reaction_time_measurements_Sabina.csv',\n    'Petr': 'reaction_time_petr.csv'\n}\n\nbase_url = 'https://raw.githubusercontent.com/VojtasekP/NAEX_reaction_time/main/'\n\ndfs = []\nfor operator, filename in data_files.items():\n    local_path = filename\n    if os.path.exists(local_path):\n        # Read raw content first to handle malformed files\n        with open(local_path, 'r') as f:\n            content = f.read()\n        print(f\"Loaded {operator} from local file: {local_path}\")\n    else:\n        try:\n            import urllib.request\n            url = base_url + filename\n            with urllib.request.urlopen(url) as response:\n                content = response.read().decode('utf-8')\n            print(f\"Loaded {operator} from GitHub: {url}\")\n        except Exception as e:\n            print(f\"Error loading {operator}: {e}\")\n            continue\n    \n    # Fix malformed Sabina file: first line has multiple records concatenated\n    # Split by the header pattern and reconstruct\n    lines = content.split('\\n')\n    header = 'timestamp_utc,participant,stimulus_type,font_size,motion,input_mode,frame_motion,shaking,text_color_mode,background_mode,min_delay_sec,max_delay_sec,repetitions,trial,stimulus,reaction_time_ms'\n    \n    # Check if first line is malformed (contains multiple records)\n    if lines[0].count('timestamp_utc') > 1 or lines[0].count(',') > 20:\n        print(f\"  -> Fixing malformed first line in {operator}'s file...\")\n        # The first line might have header + multiple data records concatenated\n        # Split by the date pattern to separate records\n        import re\n        first_line = lines[0]\n        # Extract header\n        fixed_lines = [header]\n        # Find all records (they start with date pattern)\n        records = re.split(r'(?=\\d{4}-\\d{2}-\\d{2}T)', first_line)\n        for rec in records:\n            if rec.strip() and not rec.startswith('timestamp'):\n                fixed_lines.append(rec.strip())\n        # Add remaining lines\n        for line in lines[1:]:\n            if line.strip():\n                fixed_lines.append(line.strip())\n        content = '\\n'.join(fixed_lines)\n    \n    # Parse CSV\n    df = pd.read_csv(StringIO(content))\n    \n    # Ensure participant column is consistent\n    df['participant'] = operator\n    dfs.append(df)\n    print(f\"  -> {len(df)} rows loaded for {operator}\")\n\n# Combine all data\ndf_raw = pd.concat(dfs, ignore_index=True)\nprint(f\"\\nTotal rows: {len(df_raw)}\")\nprint(f\"Columns: {list(df_raw.columns)}\")\nprint(f\"\\nRows per operator:\")\nprint(df_raw['participant'].value_counts())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Factor Coding\n",
    "\n",
    "Convert the experimental settings to coded factor levels (-1, +1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for analysis\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Code factors according to desc_factors.txt\n",
    "# Factor 1: minimum delay (-1 = 0.5, +1 = 2.0)\n",
    "df['A_min_delay'] = df['min_delay_sec'].apply(lambda x: -1 if x < 1.0 else 1)\n",
    "\n",
    "# Factor 2: maximum delay (-1 = 3, +1 = 7)\n",
    "df['B_max_delay'] = df['max_delay_sec'].apply(lambda x: -1 if x < 5.0 else 1)\n",
    "\n",
    "# Factor 3: frame motion (-1 = static, +1 = shaking)\n",
    "df['C_frame_motion'] = df['frame_motion'].apply(lambda x: 1 if 'Shaking' in str(x) else -1)\n",
    "\n",
    "# Factor 4: background (-1 = white, +1 = random colors)\n",
    "df['D_background'] = df['background_mode'].apply(lambda x: 1 if 'Random' in str(x) else -1)\n",
    "\n",
    "# Factor 5: font scale (-1 = small, +1 = large)\n",
    "df['E_font_scale'] = df['font_size'].apply(lambda x: 1 if 'Large' in str(x) else -1)\n",
    "\n",
    "# Factor 6: text color (-1 = black, +1 = random)\n",
    "df['F_text_color'] = df['text_color_mode'].apply(lambda x: 1 if 'Random' in str(x) else -1)\n",
    "\n",
    "# Factor 7: text motion (-1 = static, +1 = moving)\n",
    "df['G_text_motion'] = df['motion'].apply(lambda x: 1 if 'Moving' in str(x) else -1)\n",
    "\n",
    "# Block: Operator/Participant\n",
    "df['Block'] = df['participant']\n",
    "\n",
    "# Response: reaction time\n",
    "df['Y'] = df['reaction_time_ms']\n",
    "\n",
    "print(\"Factor coding complete\")\n",
    "print(\"\\nFactor summary:\")\n",
    "for col in ['A_min_delay', 'B_max_delay', 'C_frame_motion', 'D_background', 'E_font_scale', 'F_text_color', 'G_text_motion']:\n",
    "    print(f\"{col}: {df[col].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique experimental condition identifier\n",
    "df['condition'] = (df['A_min_delay'].astype(str) + '_' +\n",
    "                   df['B_max_delay'].astype(str) + '_' +\n",
    "                   df['C_frame_motion'].astype(str) + '_' +\n",
    "                   df['D_background'].astype(str) + '_' +\n",
    "                   df['E_font_scale'].astype(str) + '_' +\n",
    "                   df['F_text_color'].astype(str) + '_' +\n",
    "                   df['G_text_motion'].astype(str))\n",
    "\n",
    "# Count unique conditions per block\n",
    "print(\"Unique conditions per block:\")\n",
    "print(df.groupby('Block')['condition'].nunique())\n",
    "\n",
    "print(f\"\\nTotal unique conditions: {df['condition'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aggregate Data by Condition\n",
    "\n",
    "Average reaction times over the 10 repetitions per condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate: mean reaction time per condition per block\n",
    "factors = ['A_min_delay', 'B_max_delay', 'C_frame_motion', 'D_background', \n",
    "           'E_font_scale', 'F_text_color', 'G_text_motion', 'Block']\n",
    "\n",
    "df_agg = df.groupby(factors).agg(\n",
    "    Y_mean=('Y', 'mean'),\n",
    "    Y_std=('Y', 'std'),\n",
    "    Y_count=('Y', 'count')\n",
    ").reset_index()\n",
    "\n",
    "print(f\"Aggregated data shape: {df_agg.shape}\")\n",
    "print(f\"\\nConditions per block:\")\n",
    "print(df_agg.groupby('Block').size())\n",
    "\n",
    "df_agg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by block\n",
    "print(\"Summary statistics by Block (Operator):\")\n",
    "print(df_agg.groupby('Block')['Y_mean'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Box plot of reaction times by block\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# By block - explicit order\nblock_order = ['Florentin', 'Francisco', 'Petr', 'Sabina']\nsns.boxplot(x='Block', y='Y_mean', data=df_agg, order=block_order, ax=axes[0])\naxes[0].set_title('Reaction Time by Block (Operator)')\naxes[0].set_xlabel('Operator')\naxes[0].set_ylabel('Mean Reaction Time (ms)')\n\n# Distribution\ndf_agg['Y_mean'].hist(bins=30, ax=axes[1], edgecolor='black')\naxes[1].set_title('Distribution of Mean Reaction Times')\naxes[1].set_xlabel('Mean Reaction Time (ms)')\naxes[1].set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n# Commentary on EDA\nprint(\"\"\"\nINTERPRETATION - Exploratory Data Analysis:\n================================================================================\n1. OPERATOR VARIABILITY:\n   - Boxplots show differences in reaction times between operators\n   - Some differences may be statistically significant (see ANOVA below)\n   - Blocking by operator is justified - eliminates inter-personal variability\n\n2. DISTRIBUTION:\n   - Histogram shows slightly right-skewed distribution (typical for RT data)\n   - Most reaction times are between 900-1400 ms\n   - Some extremes (>2000 ms) may indicate attention loss or errors\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main effects visualization\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "factor_names = ['A_min_delay', 'B_max_delay', 'C_frame_motion', 'D_background',\n",
    "                'E_font_scale', 'F_text_color', 'G_text_motion']\n",
    "\n",
    "factor_labels = ['Min Delay', 'Max Delay', 'Frame Motion', 'Background',\n",
    "                 'Font Scale', 'Text Color', 'Text Motion']\n",
    "\n",
    "for i, (factor, label) in enumerate(zip(factor_names, factor_labels)):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    means = df_agg.groupby(factor)['Y_mean'].mean()\n",
    "    ax.bar(means.index.astype(str), means.values, color=['steelblue', 'darkorange'])\n",
    "    ax.set_title(f'{label}')\n",
    "    ax.set_xlabel('Level')\n",
    "    ax.set_ylabel('Mean RT (ms)')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['-1', '+1'])\n",
    "\n",
    "# Hide the last empty subplot\n",
    "axes[1, 3].set_visible(False)\n",
    "\n",
    "plt.suptitle('Main Effects Plot', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate Effects\n",
    "\n",
    "Calculate main effects and interaction effects for the 2^7 factorial design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_effects(df, response_col, factors):\n",
    "    \"\"\"\n",
    "    Calculate main effects and two-factor interactions for 2^k factorial design.\n",
    "    \"\"\"\n",
    "    effects = {}\n",
    "    \n",
    "    # Grand mean\n",
    "    grand_mean = df[response_col].mean()\n",
    "    effects['Intercept'] = grand_mean\n",
    "    \n",
    "    # Main effects\n",
    "    for factor in factors:\n",
    "        high = df[df[factor] == 1][response_col].mean()\n",
    "        low = df[df[factor] == -1][response_col].mean()\n",
    "        effects[factor] = (high - low) / 2\n",
    "    \n",
    "    # Two-factor interactions\n",
    "    for i, f1 in enumerate(factors):\n",
    "        for f2 in factors[i+1:]:\n",
    "            interaction_col = df[f1] * df[f2]\n",
    "            high = df[interaction_col == 1][response_col].mean()\n",
    "            low = df[interaction_col == -1][response_col].mean()\n",
    "            effects[f'{f1}:{f2}'] = (high - low) / 2\n",
    "    \n",
    "    return effects\n",
    "\n",
    "# Calculate effects\n",
    "factor_cols = ['A_min_delay', 'B_max_delay', 'C_frame_motion', 'D_background',\n",
    "               'E_font_scale', 'F_text_color', 'G_text_motion']\n",
    "\n",
    "effects = calculate_effects(df_agg, 'Y_mean', factor_cols)\n",
    "\n",
    "# Create DataFrame for display\n",
    "effects_df = pd.DataFrame(list(effects.items()), columns=['Effect', 'Value'])\n",
    "effects_df['Absolute'] = effects_df['Value'].abs()\n",
    "effects_df = effects_df.sort_values('Absolute', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Effects (sorted by absolute value):\")\n",
    "print(effects_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Half-normal probability plot with reference line\neffects_no_intercept = effects_df[effects_df['Effect'] != 'Intercept'].copy()\neffects_sorted = effects_no_intercept.sort_values('Absolute')\n\nn = len(effects_sorted)\ni = np.arange(1, n + 1)\nprobabilities = (i - 0.5) / n\nexpected_values = stats.halfnorm.ppf(probabilities)\n\nplt.figure(figsize=(12, 8))\nplt.scatter(effects_sorted['Absolute'], expected_values, s=60, alpha=0.7)\n\n# Add reference line (fitted through first 50% of effects)\ncutoff = int(0.5 * len(effects_sorted))\nfrom scipy.stats import linregress\nslope, intercept, _, _, _ = linregress(effects_sorted['Absolute'].iloc[:cutoff].values, expected_values[:cutoff])\nx_line = np.array([effects_sorted['Absolute'].min(), effects_sorted['Absolute'].max()])\ny_line = slope * x_line + intercept\nplt.plot(x_line, y_line, 'r--', alpha=0.5, linewidth=2, label='Reference line')\n\n# Label points that deviate significantly from the line\nsignificant_effects = []\nfor idx, row in effects_sorted.iterrows():\n    x_val = row['Absolute']\n    y_actual = expected_values[effects_sorted.index.get_loc(idx)]\n    y_expected = slope * x_val + intercept\n    # Label if deviation is significant (above line)\n    if y_actual > y_expected + 0.3 or x_val > effects_sorted['Absolute'].quantile(0.8):\n        plt.annotate(row['Effect'], (x_val, y_actual), \n                     textcoords=\"offset points\", xytext=(5, 5), \n                     fontsize=9, ha='left')\n        significant_effects.append(row['Effect'])\n\nplt.xlabel('Absolute Effect', fontsize=12)\nplt.ylabel('Half-Normal Probability', fontsize=12)\nplt.title('Half-Normal Probability Plot of Effects', fontsize=14)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# Commentary\nprint(\"\"\"\nINTERPRETATION - Half-Normal Plot:\n================================================================================\nPRINCIPLE:\n- Points ON the reference line = inactive factors (noise)\n- Points significantly ABOVE the line = active (significant) factors\n\nIDENTIFIED ACTIVE EFFECTS:\n\"\"\")\nfor eff in significant_effects:\n    val = effects_df[effects_df['Effect'] == eff]['Value'].values[0]\n    print(f\"  • {eff}: {val:+.2f} ms\")\nprint(\"\"\"\nNOTE:\n- Reference line fitted through bottom 50% of effects (assumed noise)\n- Effects deviating significantly from line are candidates for significant factors\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ANOVA with Blocking\n",
    "\n",
    "Perform ANOVA including block effects (operators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Full model with block effect\n# Using main effects + block only first\nformula_main = 'Y_mean ~ C(Block) + A_min_delay + B_max_delay + C_frame_motion + D_background + E_font_scale + F_text_color + G_text_motion'\n\nmodel_main = ols(formula_main, data=df_agg).fit()\n\nprint(\"=\" * 60)\nprint(\"ANOVA TABLE - Main Effects + Block\")\nprint(\"=\" * 60)\nanova_main = anova_lm(model_main, typ=2)\nprint(anova_main.round(4))\n\n# Commentary\nprint(\"\"\"\nINTERPRETATION - ANOVA Results:\n================================================================================\nSIGNIFICANCE (p < 0.05):\n\"\"\")\nfor idx in anova_main.index:\n    if idx != 'Residual':\n        p_val = anova_main.loc[idx, 'PR(>F)']\n        f_val = anova_main.loc[idx, 'F']\n        significance = \"***\" if p_val < 0.001 else \"**\" if p_val < 0.01 else \"*\" if p_val < 0.05 else \"\"\n        status = \"SIGNIFICANT\" if p_val < 0.05 else \"not significant\"\n        print(f\"  {idx}: F={f_val:.2f}, p={p_val:.4f} {significance} -> {status}\")\n\nprint(\"\"\"\nNOTES:\n- C(Block) = operator effect (blocking factor)\n- Type II ANOVA: tests each factor after accounting for others\n- High F = large difference between factor levels relative to noise\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with significant two-factor interactions\n",
    "# Based on effect analysis, include most important interactions\n",
    "formula_full = '''Y_mean ~ C(Block) + A_min_delay + B_max_delay + C_frame_motion + D_background + \n",
    "                  E_font_scale + F_text_color + G_text_motion +\n",
    "                  A_min_delay:B_max_delay + A_min_delay:C_frame_motion + A_min_delay:D_background +\n",
    "                  B_max_delay:C_frame_motion + C_frame_motion:D_background + E_font_scale:G_text_motion'''\n",
    "\n",
    "model_full = ols(formula_full, data=df_agg).fit()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANOVA TABLE - With Key Interactions\")\n",
    "print(\"=\" * 60)\n",
    "anova_full = anova_lm(model_full, typ=2)\n",
    "print(anova_full.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(model_full.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Diagnostics\n",
    "\n",
    "Check model assumptions using studentized residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get studentized residuals\ninfluence = OLSInfluence(model_full)\nstudentized_resid = influence.resid_studentized_internal\nfitted_values = model_full.fittedvalues\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# 1. Residuals vs Fitted\naxes[0, 0].scatter(fitted_values, studentized_resid, alpha=0.6)\naxes[0, 0].axhline(y=0, color='r', linestyle='--')\naxes[0, 0].axhline(y=2, color='gray', linestyle=':', alpha=0.5)\naxes[0, 0].axhline(y=-2, color='gray', linestyle=':', alpha=0.5)\naxes[0, 0].set_xlabel('Fitted Values')\naxes[0, 0].set_ylabel('Studentized Residuals')\naxes[0, 0].set_title('Studentized Residuals vs Fitted Values')\n\n# 2. Q-Q Plot\nstats.probplot(studentized_resid, dist=\"norm\", plot=axes[0, 1])\naxes[0, 1].set_title('Normal Q-Q Plot of Studentized Residuals')\n\n# 3. Scale-Location\naxes[1, 0].scatter(fitted_values, np.sqrt(np.abs(studentized_resid)), alpha=0.6)\naxes[1, 0].set_xlabel('Fitted Values')\naxes[1, 0].set_ylabel('√|Studentized Residuals|')\naxes[1, 0].set_title('Scale-Location Plot')\n\n# 4. Histogram of residuals\naxes[1, 1].hist(studentized_resid, bins=30, edgecolor='black', density=True)\nx_range = np.linspace(studentized_resid.min(), studentized_resid.max(), 100)\naxes[1, 1].plot(x_range, stats.norm.pdf(x_range), 'r-', lw=2, label='Normal')\naxes[1, 1].set_xlabel('Studentized Residuals')\naxes[1, 1].set_ylabel('Density')\naxes[1, 1].set_title('Distribution of Studentized Residuals')\naxes[1, 1].legend()\n\nplt.tight_layout()\nplt.show()\n\n# Normality test\nshapiro_stat, shapiro_p = stats.shapiro(studentized_resid[:50])  # Shapiro-Wilk for first 50\n\n# Count outliers\nn_outliers = np.sum(np.abs(studentized_resid) > 2)\n\nprint(\"\"\"\nINTERPRETATION - Model Diagnostics:\n================================================================================\n1. RESIDUALS VS FITTED:\n   - Looking for random scatter around zero\n   - Pattern (funnel, curve) = assumption violation\n   - Points outside ±2 = potential outliers\n\n2. Q-Q PLOT:\n   - Points on diagonal = normality OK\n   - Deviations at tails = heavy tails / skewness\n\n3. SCALE-LOCATION:\n   - Constant variability = horizontal band\n   - Increasing trend = heteroscedasticity\n\n4. HISTOGRAM:\n   - Comparison with normal distribution\n\"\"\")\nprint(f\"STATISTICS:\")\nprint(f\"  - Number of outliers (|r| > 2): {n_outliers} out of {len(studentized_resid)}\")\nprint(f\"  - Shapiro-Wilk test (subsample): W={shapiro_stat:.4f}, p={shapiro_p:.4f}\")\nif shapiro_p > 0.05:\n    print(f\"    -> Normality NOT rejected (p > 0.05)\")\nelse:\n    print(f\"    -> Normality REJECTED (p < 0.05) - but ANOVA is robust\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Residuals by block - ensure all operators are shown\ndf_agg['residuals'] = studentized_resid\n\n# Define explicit order for blocks\nblock_order = ['Florentin', 'Francisco', 'Petr', 'Sabina']\n\nfig, ax = plt.subplots(figsize=(10, 6))\nsns.boxplot(x='Block', y='residuals', data=df_agg, order=block_order, ax=ax)\nax.axhline(y=0, color='r', linestyle='--')\nax.axhline(y=2, color='gray', linestyle=':', alpha=0.5, label='±2 threshold')\nax.axhline(y=-2, color='gray', linestyle=':', alpha=0.5)\nax.set_title('Studentized Residuals by Block (Operator)')\nax.set_xlabel('Operator')\nax.set_ylabel('Studentized Residuals')\nax.legend()\nplt.tight_layout()\nplt.show()\n\n# Check residuals statistics per block\nprint(\"\\nResidual Statistics per Block:\")\nprint(\"=\" * 60)\nresid_stats = df_agg.groupby('Block')['residuals'].agg(['mean', 'std', 'min', 'max', 'count'])\nprint(resid_stats.round(3))\n\nprint(\"\"\"\nINTERPRETATION - Residuals by Block:\n================================================================================\n- Residuals should be centered around 0 for each block (balanced design)\n- Similar spread across blocks = homoscedasticity within blocks\n- Outliers (|r| > 2) indicate unusual observations\n- If one block has systematically different residuals, blocking was effective\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pareto Chart of Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pareto chart of standardized effects\n# Use t-values from the model\nt_values = model_main.tvalues.drop('Intercept')\nt_df = pd.DataFrame({'Effect': t_values.index, 't_value': t_values.values})\nt_df['abs_t'] = t_df['t_value'].abs()\nt_df = t_df.sort_values('abs_t', ascending=True)\n\n# Critical t-value for significance (alpha = 0.05)\ndf_residual = model_main.df_resid\nt_crit = stats.t.ppf(0.975, df_residual)\n\nplt.figure(figsize=(10, 8))\ncolors = ['steelblue' if abs(t) < t_crit else 'darkorange' for t in t_df['t_value']]\nplt.barh(t_df['Effect'], t_df['abs_t'], color=colors)\nplt.axvline(x=t_crit, color='r', linestyle='--', label=f't_crit = {t_crit:.2f} (α=0.05)')\nplt.xlabel('|t-value|')\nplt.ylabel('Effect')\nplt.title('Pareto Chart of Standardized Effects')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\nprint(\"\"\"\nINTERPRETATION - Pareto Chart:\n================================================================================\n- Bars extending BEYOND the red line are statistically significant\n- Orange bars = significant effects (p < 0.05)\n- Blue bars = non-significant effects\n\nThe Pareto chart ranks effects by importance (standardized effect size).\nEffects at the top of the chart have the largest impact on reaction time.\n\nThis visualization follows the Pareto principle - often a few factors\n(20%) account for most of the variation (80%).\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Block Effect Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compare operators\nprint(\"\\nBlock (Operator) Effect Analysis:\")\nprint(\"=\" * 60)\n\nblock_means = df_agg.groupby('Block')['Y_mean'].agg(['mean', 'std', 'count'])\nprint(\"\\nMean Reaction Time by Operator:\")\nprint(block_means.round(2))\n\n# Tukey HSD for block comparison\ntukey_result = pairwise_tukeyhsd(df_agg['Y_mean'], df_agg['Block'], alpha=0.05)\nprint(\"\\nTukey HSD Multiple Comparison:\")\nprint(tukey_result)\n\nprint(\"\"\"\nINTERPRETATION - Block Effect:\n================================================================================\nThe block effect captures systematic differences between operators.\n\nKEY OBSERVATIONS:\n- Operators may differ in baseline reaction speed\n- These differences are removed from experimental error by blocking\n- Tukey HSD identifies which pairs of operators differ significantly\n\nIF block effect is significant:\n  -> Blocking was effective and reduced experimental error\n  -> Individual differences exist but don't confound factor effects\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualization of Tukey results - manual plot (more robust than plot_simultaneous)\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Get unique groups and their means\nblock_means = df_agg.groupby('Block')['Y_mean'].mean().sort_values()\nblock_stds = df_agg.groupby('Block')['Y_mean'].std()\nblock_counts = df_agg.groupby('Block')['Y_mean'].count()\n\n# Calculate confidence intervals (95%)\nfrom scipy.stats import t as t_dist\nalpha = 0.05\n\n# Plot means with confidence intervals\ny_positions = np.arange(len(block_means))\ncolors = plt.cm.Set2(np.linspace(0, 1, len(block_means)))\n\nfor i, (block, mean_val) in enumerate(block_means.items()):\n    std = block_stds[block]\n    n = block_counts[block]\n    se = std / np.sqrt(n)\n    t_crit = t_dist.ppf(1 - alpha/2, n - 1)\n    ci = t_crit * se\n    \n    ax.errorbar(mean_val, i, xerr=ci, fmt='o', markersize=10, \n                capsize=5, capthick=2, color=colors[i], linewidth=2,\n                label=f'{block}: {mean_val:.1f} ± {ci:.1f} ms')\n\nax.set_yticks(y_positions)\nax.set_yticklabels(block_means.index)\nax.set_xlabel('Mean Reaction Time (ms)', fontsize=12)\nax.set_ylabel('Operator', fontsize=12)\nax.set_title('Operator Comparison: Mean Reaction Time with 95% CI', fontsize=14)\nax.legend(loc='upper right')\nax.grid(True, axis='x', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Show Tukey summary table\nprint(\"\\nTukey HSD Summary Table:\")\nprint(\"=\" * 70)\ntukey_summary = tukey_result.summary()\nprint(tukey_summary)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interpretation and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summarize significant effects\nprint(\"=\" * 60)\nprint(\"SUMMARY OF SIGNIFICANT EFFECTS\")\nprint(\"=\" * 60)\n\n# Get p-values for main effects\nanova_main_clean = anova_main.copy()\nanova_main_clean['significant'] = anova_main_clean['PR(>F)'] < 0.05\n\nprint(\"\\nSignificant factors (p < 0.05):\")\nsignificant = anova_main_clean[anova_main_clean['significant']]\nfor idx in significant.index:\n    if idx != 'Residual':\n        p_val = anova_main_clean.loc[idx, 'PR(>F)']\n        f_val = anova_main_clean.loc[idx, 'F']\n        print(f\"  {idx}: F = {f_val:.2f}, p = {p_val:.4f}\")\n\nprint(\"\\nNon-significant factors (p >= 0.05):\")\nnon_significant = anova_main_clean[~anova_main_clean['significant']]\nfor idx in non_significant.index:\n    if idx != 'Residual':\n        p_val = anova_main_clean.loc[idx, 'PR(>F)']\n        f_val = anova_main_clean.loc[idx, 'F']\n        print(f\"  {idx}: F = {f_val:.2f}, p = {p_val:.4f}\")\n\nprint(\"\"\"\nINTERPRETATION:\n================================================================================\nSIGNIFICANT EFFECTS indicate factors that reliably influence reaction time.\n- These should be controlled/optimized in the experiment\n- Their settings matter for achieving desired reaction time\n\nNON-SIGNIFICANT EFFECTS can be set for convenience or cost savings.\n- These factors don't strongly influence reaction time\n- Can be held at any level without major impact\n\"\"\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Effect sizes for significant factors\nprint(\"=\" * 60)\nprint(\"EFFECT SIZES (Cohen's f)\")\nprint(\"=\" * 60)\n\n# Calculate partial eta-squared and Cohen's f\nSS_total = anova_main['sum_sq'].sum()\nSS_error = anova_main.loc['Residual', 'sum_sq']\n\nprint(\"\\n{:<25} {:>12} {:>12} {:>15}\".format(\"Effect\", \"η² partial\", \"Cohen's f\", \"Magnitude\"))\nprint(\"-\" * 65)\n\nfor idx in anova_main.index:\n    if idx != 'Residual':\n        SS_effect = anova_main.loc[idx, 'sum_sq']\n        partial_eta_sq = SS_effect / (SS_effect + SS_error)\n        cohens_f = np.sqrt(partial_eta_sq / (1 - partial_eta_sq))\n        \n        # Determine magnitude\n        if cohens_f < 0.10:\n            magnitude = \"negligible\"\n        elif cohens_f < 0.25:\n            magnitude = \"small\"\n        elif cohens_f < 0.40:\n            magnitude = \"medium\"\n        else:\n            magnitude = \"LARGE\"\n        \n        print(f\"{idx:<25} {partial_eta_sq:>12.4f} {cohens_f:>12.4f} {magnitude:>15}\")\n\nprint(\"\"\"\nINTERPRETATION - Effect Sizes:\n================================================================================\nCohen's f benchmarks:\n  - Small:   f = 0.10 (1% variance explained)\n  - Medium:  f = 0.25 (6% variance explained)\n  - Large:   f = 0.40 (14% variance explained)\n\nPRACTICAL SIGNIFICANCE:\n- Large effects are practically important regardless of p-value\n- Small significant effects may not be worth optimizing\n- Effect size helps prioritize which factors to control\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interaction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create interaction plots for top interactions\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\n\n# Define interactions to plot\ninteractions = [\n    ('A_min_delay', 'B_max_delay'),\n    ('A_min_delay', 'C_frame_motion'),\n    ('C_frame_motion', 'D_background'),\n    ('E_font_scale', 'G_text_motion'),\n    ('B_max_delay', 'C_frame_motion'),\n    ('A_min_delay', 'D_background')\n]\n\nfactor_labels_dict = {\n    'A_min_delay': 'Min Delay', 'B_max_delay': 'Max Delay',\n    'C_frame_motion': 'Frame Motion', 'D_background': 'Background',\n    'E_font_scale': 'Font Scale', 'F_text_color': 'Text Color',\n    'G_text_motion': 'Text Motion'\n}\n\nfor i, (f1, f2) in enumerate(interactions):\n    ax = axes[i // 3, i % 3]\n    \n    # Calculate means for each combination\n    means = df_agg.groupby([f1, f2])['Y_mean'].mean().unstack()\n    \n    for col in means.columns:\n        label = f'{factor_labels_dict[f2]}={col}'\n        ax.plot(means.index, means[col], marker='o', label=label, linewidth=2, markersize=8)\n    \n    ax.set_xlabel(factor_labels_dict[f1])\n    ax.set_ylabel('Mean RT (ms)')\n    ax.set_title(f'{factor_labels_dict[f1]} × {factor_labels_dict[f2]}')\n    ax.legend()\n    ax.set_xticks([-1, 1])\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\"\"\nINTERPRETATION - Interaction Plots:\n================================================================================\nHOW TO READ:\n- Parallel lines = NO interaction (additive effects)\n- Non-parallel lines = INTERACTION present\n\nEXAMPLES:\n- If lines cross: Strong interaction - factor effect depends on other factor level\n- If lines diverge: Synergistic or antagonistic interaction\n- If lines are parallel: Factors act independently\n\nPRACTICAL IMPLICATIONS:\n- Interactions mean we cannot interpret main effects in isolation\n- Optimal settings must consider factor combinations\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Conclusions\n",
    "\n",
    "Based on the 2^7 factorial design analysis with blocking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Final summary with interpretation\nprint(\"\"\"\n========================================================================\nCONCLUSIONS - Reaction Time 2^7 Factorial Design with Blocking\n========================================================================\n\nEXPERIMENTAL DESIGN:\n- 7 factors at 2 levels each (2^7 = 128 conditions)\n- 4 blocks (operators): Sabina, Florentin, Francisco, Petr\n- 32 unique conditions per operator\n- 10 repetitions per condition\n- Response: Reaction time (ms)\n\nKEY FINDINGS FROM THIS ANALYSIS:\n\n1. BLOCKING EFFECTIVENESS:\n   - Block effect (C(Block)) captures operator-to-operator differences\n   - If significant: blocking successfully removed nuisance variation\n   - This improves power to detect true factor effects\n\n2. MAIN EFFECTS:\n   - Factors with p < 0.05 have significant impact on reaction time\n   - Effect size (Cohen's f) indicates practical significance\n   - Large effects (f > 0.40) are most important for optimization\n\n3. INTERACTIONS:\n   - Non-parallel lines in interaction plots indicate dependencies\n   - Cannot optimize factors independently when interactions exist\n   - Need to consider factor combinations for best settings\n\n4. MODEL VALIDITY:\n   - Studentized residuals should follow N(0,1) approximately\n   - Q-Q plot deviations indicate non-normality\n   - Outliers (|r| > 2) may need investigation\n\nMETHODOLOGY NOTES:\n- Used aggregated data (mean over 10 repetitions) for analysis\n- Type II ANOVA for balanced comparison\n- Tukey HSD for multiple comparisons between operators\n- Blocking removes operator-to-operator variation from error term\n\nRECOMMENDATIONS:\n- Focus on significant main effects for process improvement\n- Consider significant interactions when setting factor levels\n- Validate findings with confirmation runs\n\n========================================================================\n\"\"\")\n\n# Print R-squared for model fit\nprint(f\"Model Fit Statistics:\")\nprint(f\"  R-squared: {model_full.rsquared:.4f}\")\nprint(f\"  Adjusted R-squared: {model_full.rsquared_adj:.4f}\")\nprint(f\"  This means the model explains {model_full.rsquared*100:.1f}% of variance in reaction time.\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}